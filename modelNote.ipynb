{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 16:57:22,225 - modelscope - INFO - PyTorch version 2.0.1+cu117 Found.\n",
      "2023-10-14 16:57:22,230 - modelscope - INFO - TensorFlow version 2.14.0 Found.\n",
      "2023-10-14 16:57:22,231 - modelscope - INFO - Loading ast index from C:\\Users\\Олег\\.cache\\modelscope\\ast_indexer\n",
      "2023-10-14 16:57:22,431 - modelscope - INFO - Loading done! Current index file version is 1.9.2, with md5 d900a8624d792d555ed3cef91c01c35b and a total number of 941 components indexed\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from mmocr.apis import MMOCRInferencer\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "'''\n",
    "    detection_mode: ./models/custom_yolov8pt_25_orig.pt\n",
    "    rec_model: damo/cv_convnextTiny_ocr-recognition-general_damo\n",
    "    angle_rec_model: Aster\n",
    "'''\n",
    "\n",
    "DETECTION_SAVE_PATH = './yolo_detections/results/crops/number/'\n",
    "MODEL_RESULT_PATH = './model_result/results.csv'\n",
    "\n",
    "BIN_TYPES = {\n",
    "    'ADAPTIVE_THRESH_GAUSSIAN_C': cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    'ADAPTIVE_THRESH_MEAN_C': cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    'THRESH_OTSU': cv2.THRESH_OTSU\n",
    "}\n",
    "\n",
    "# def get_center(bbox):\n",
    "#     return np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n",
    "#\n",
    "# def is_border_num(result, image_path):\n",
    "#         for i in range(len(result)):\n",
    "#             boxes = result[i].boxes.cpu().numpy()\n",
    "#             for box in boxes:\n",
    "#                 center = get_center(box.xyxy[0])\n",
    "#\n",
    "#\n",
    "#                 img = cv2.imread(image_path)\n",
    "#\n",
    "#                 if center[0] < (img.shape[1] / 10) or center[0] > (img.shape[1] / 10) * 9:\n",
    "#                     return True\n",
    "#             return False\n",
    "\n",
    "\n",
    "class NumberOcrModel:\n",
    "    def __init__(self, detection_model, rec_model, angle_rec_model):\n",
    "        self.detection_model = YOLO(detection_model)\n",
    "        self.rec_model = pipeline(Tasks.ocr_recognition, model=rec_model)\n",
    "        self.angle_rec_model = MMOCRInferencer(rec=angle_rec_model)\n",
    "\n",
    "        self.detection_result = None\n",
    "        self.img_path = None\n",
    "        self.image_name = None\n",
    "        self.bin_type = None\n",
    "        self.rec_result = None\n",
    "\n",
    "        self.prepare_model()\n",
    "\n",
    "    def prepare_model(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.detection_model.to('cuda')\n",
    "\n",
    "    def preprocess(self, image_path, image_name, bin_prep):\n",
    "        detection_result = self.detection_model.predict(image_path, save = True, save_crop=True, project='yolo_detections', name='results', verbose=False)\n",
    "\n",
    "        if detection_result and bin_prep:\n",
    "            img = cv2.imread(DETECTION_SAVE_PATH + image_name)\n",
    "            blur_img = cv2.GaussianBlur(img,(1,1),0)\n",
    "            bin_img = cv2.adaptiveThreshold(blur_img, 255, BIN_TYPES[bin_prep], cv2.THRESH_BINARY_INV, 29, -4)\n",
    "            cv2.imwrite(DETECTION_SAVE_PATH + image_name, bin_img)\n",
    "        return detection_result\n",
    "\n",
    "\n",
    "    def recognize(self, image_name, image_path, detected_data):\n",
    "        if not detected_data[0] or len(detected_data[0].cpu().numpy()) == 0:\n",
    "            # return [{\n",
    "            #     'filename': image_name,\n",
    "            #     'type': 0,\n",
    "            #     'number': 0,\n",
    "            #     'is_correct': 0,\n",
    "            #     'model': 'Recognition_model',\n",
    "            #     'is_correct_rec': False\n",
    "            # },\n",
    "            # {\n",
    "            #     'filename': image_name,\n",
    "            #     'type': 0,\n",
    "            #     'number': 0,\n",
    "            #     'is_correct': 0,\n",
    "            #     'model': 'Angle_recognition_model',\n",
    "            #     'is_correct_rec': False\n",
    "            # }]\n",
    "\n",
    "            return [\n",
    "                {\n",
    "                    'filename': image_name,\n",
    "                    'type': 0,\n",
    "                    'number': 0,\n",
    "                    'is_correct': 0,\n",
    "                    'model': '-',\n",
    "                    'is_correct_rec': False\n",
    "                }]\n",
    "\n",
    "        all_dirs = os.listdir('./yolo_detections')\n",
    "        max_length = len(max(all_dirs, key=len))\n",
    "        data_dir = sorted([x for x in all_dirs if len(x) == max_length])[-1]\n",
    "\n",
    "        crop_img_path = f'./yolo_detections/{data_dir}/crops/number/' + image_name\n",
    "\n",
    "        # if is_border_num(detected_data, image_path):\n",
    "        #     result = self.angle_rec_model(crop_img_path)\n",
    "        #     num =  re.sub(r'[^0-9]', '', result['predictions'][0]['rec_texts'][0])\n",
    "        #     model = 'Angle_recognition_model'\n",
    "        # else:\n",
    "        #     result = self.rec_model(crop_img_path)\n",
    "        #     num = re.sub(r'[^0-9]', '', result['text'][0])\n",
    "        #     model = 'Recognition_model'\n",
    "\n",
    "\n",
    "        result_1 = self.angle_rec_model(crop_img_path)\n",
    "        result_2 = self.rec_model(crop_img_path)\n",
    "\n",
    "        num_1 = re.sub(r'[^0-9]', '', result_1['predictions'][0]['rec_texts'][0]) # aster\n",
    "        num_2 = re.sub(r'[^0-9]', '', result_2['text'][0]) # model scope\n",
    "\n",
    "\n",
    "        if not num_2:\n",
    "            num_sub = num_1\n",
    "        elif num_1:\n",
    "            if len(num_2) >= 8:\n",
    "                num_sub = num_2[:8]\n",
    "            if len(num_2) < 8 and len(num_1) >= 8:\n",
    "                num_sub = num_1[:8]\n",
    "            if len(num_2) < 8 and len(num_1) < 8:\n",
    "                num_sub = num_2\n",
    "\n",
    "\n",
    "        # rec_result = self.rec_model(crop_img_path)\n",
    "        # angle_rec_result = self.angle_rec_model(crop_img_path)\n",
    "\n",
    "        # num_1 = re.sub(r'[^0-9]', '', rec_result['text'][0])\n",
    "        # num_2 =  re.sub(r'[^0-9]', '', angle_rec_result['predictions'][0]['rec_texts'][0])\n",
    "\n",
    "\n",
    "        # result = [\n",
    "        #     {\n",
    "        #         'filename': image_name,\n",
    "        #         'type': (0, 1)[len(num_1) > 0],\n",
    "        #         'number': num_1,\n",
    "        #         'is_correct': is_valid(num_1),\n",
    "        #         'model': 'Recognition_model',\n",
    "        #         'is_correct_rec': num_1 == image_name[:-4]\n",
    "        #     },\n",
    "        #     {\n",
    "        #         'filename': image_name,\n",
    "        #         'type': (0, 1)[len(num_2) > 0],\n",
    "        #         'number': num_2,\n",
    "        #         'is_correct': is_valid(num_2),\n",
    "        #         'model': 'Angle_recognition_model',\n",
    "        #         'is_correct_rec': num_2 == image_name[:-4]\n",
    "        #     }\n",
    "        # ]\n",
    "\n",
    "        result = [{\n",
    "                'filename': image_name,\n",
    "                'type': int(num_sub != None),\n",
    "                'number': (0, num_sub)[num_sub != None],\n",
    "                'is_correct': is_valid(num_sub),\n",
    "                # 'model': model,\n",
    "                # 'is_correct_rec': num_sub == image_name[:-4]\n",
    "        }]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, img_path, bin_prep = None):\n",
    "        image_name = os.path.basename(os.path.normpath(img_path))\n",
    "        detected_data = self.preprocess(img_path, image_name, bin_prep)\n",
    "        return self.recognize(image_name, img_path, detected_data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:10:34,718 - modelscope - INFO - Model revision not specified, use revision: v2.3.0\n",
      "2023-10-14 17:10:35,925 - modelscope - INFO - initiate model from C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 17:10:35,926 - modelscope - INFO - initiate model from location C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo.\n",
      "2023-10-14 17:10:35,930 - modelscope - INFO - initialize model from C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 17:10:36,259 - modelscope - INFO - loading model from dir C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 17:10:36,440 - modelscope - INFO - loading model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmocr/textrecog/aster/aster_resnet45_6e_st_mj/aster_resnet45_6e_st_mj-cc56eca4.pth\n",
      "10/14 17:10:43 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - Failed to search registry with scope \"mmocr\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmocr\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\temp\\Anaconda\\lib\\site-packages\\mmengine\\visualization\\visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "model = NumberOcrModel(\n",
    "    detection_model='./models/best(6).pt',  # best(6).pt ./models/custom_yolov8pt_25_orig.pt\n",
    "    rec_model='damo/cv_convnextTiny_ocr-recognition-general_damo',\n",
    "    angle_rec_model='Aster'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results734\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': 'NONE11.jpg', 'type': 0, 'number': 0, 'is_correct': 0, 'model': 'Recognition_model', 'is_correct_rec': False}, {'filename': 'NONE11.jpg', 'type': 0, 'number': 0, 'is_correct': 0, 'model': 'Angle_recognition_model', 'is_correct_rec': False}]\n"
     ]
    }
   ],
   "source": [
    "test_res = model.predict('./data/NONE11.jpg')\n",
    "print(test_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'filename': 'NONE11.jpg',\n  'type': 0,\n  'number': 0,\n  'is_correct': 0,\n  'model': 'Recognition_model',\n  'is_correct_rec': False},\n {'filename': 'NONE11.jpg',\n  'type': 0,\n  'number': 0,\n  'is_correct': 0,\n  'model': 'Angle_recognition_model',\n  'is_correct_rec': False}]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def is_valid(result):\n",
    "    if not result:\n",
    "        return 0\n",
    "\n",
    "    cont_sum = 0\n",
    "    control_num = -1\n",
    "\n",
    "    if len(result) == 8:\n",
    "        control_num = int(result[-1:])\n",
    "        cont_sum = 0\n",
    "        for i in range(7):\n",
    "            num = int(result[i]) * (2, 1)[i % 2 == 1]\n",
    "            if num >= 10:\n",
    "                cont_sum += sum(list(map(int, set(str(num)))))\n",
    "            else:\n",
    "                cont_sum += num\n",
    "    return int((cont_sum % 10 == 0 and control_num == 0) or (10 - cont_sum % 10) == control_num)\n",
    "\n",
    "\n",
    "def to_csv(results):\n",
    "    with open(MODEL_RESULT_PATH, 'w', encoding='UTF8') as f:\n",
    "        fields = ('filename', 'type', 'number', 'is_correct')  # 'model', 'is_correct_rec'\n",
    "        writer = csv.DictWriter(f, fieldnames=fields, lineterminator = '\\n')\n",
    "        writer.writeheader()\n",
    "        for res in results:\n",
    "            writer.writerow(res[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results862\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbca7819872248bb8f45647ab67c6cf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results863\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1374189f1ffd40ecbbd3ece173af9186"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results864\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05bb27282c964546ac84352e9933cea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results865\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfb01b5203ec4dbcb234d4baa33de607"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results866\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15dfb01418fa4ec68b29b12e887c8006"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results867\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6d8601b473d4c18ad1103b07d855516"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results868\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed0b95a78a414a1faf1e55ea89928e51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results869\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0600575e463944ab9e219452afabd055"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results870\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a9941b02f324051b546a7c8e24db09f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       filename  type    number  is_correct              model  is_correct_rec\n",
      "0  28005312.jpg     1  28005312           1  Recognition_model            True\n",
      "1  28008332.jpg     1  28008332           1  Recognition_model            True\n",
      "2  28025021.jpg     1  28025021           1  Recognition_model            True\n",
      "3  29025210.jpg     1  29025210           1  Recognition_model            True\n",
      "4  29029972.jpg     1  29029972           1  Recognition_model            True\n",
      "5  29051091.jpg     1  29051091           1  Recognition_model            True\n",
      "6  42026633.jpg     1  42026633           1  Recognition_model            True\n",
      "7  42026781.jpg     1  42026781           1  Recognition_model            True\n",
      "8  42026872.jpg     1  42026872           1  Recognition_model            True\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './test_images/'\n",
    "\n",
    "images = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(DATA_PATH):\n",
    "    images.extend(filenames)\n",
    "\n",
    "results = []\n",
    "\n",
    "for img in images:\n",
    "    res = model.predict(DATA_PATH + img)\n",
    "    if res:\n",
    "        results.append(res)\n",
    "\n",
    "to_csv(results)\n",
    "\n",
    "file = pd.read_csv(MODEL_RESULT_PATH)\n",
    "print(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "line = re.sub(r'[^0-9]', '', '1,2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "line"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = 'sdfsdf.jpg'\n",
    "a[:-4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "file = pd.read_csv(MODEL_RESULT_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "rec = file[file['model'] == 'Recognition_model']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "          filename  type      number  is_correct              model  \\\n0     24252710.jpg     1  24252710.0           0  Recognition_model   \n2     24295479.jpg     1  24295479.0           1  Recognition_model   \n4     24353013.jpg     1  24353013.0           1  Recognition_model   \n6     24424020.jpg     1  24424020.0           0  Recognition_model   \n8     24432064.jpg     1  24432064.0           1  Recognition_model   \n...            ...   ...         ...         ...                ...   \n1446  98091358.jpg     1  98091358.0           1  Recognition_model   \n1448  98101173.jpg     1  98101173.0           1  Recognition_model   \n1450  98104730.jpg     1  98104730.0           0  Recognition_model   \n1454  98121817.jpg     1  98121817.0           1  Recognition_model   \n1456  98121833.jpg     1  98121833.0           1  Recognition_model   \n\n      is_correct_rec  \n0               True  \n2               True  \n4               True  \n6               True  \n8               True  \n...              ...  \n1446            True  \n1448            True  \n1450            True  \n1454            True  \n1456            True  \n\n[500 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>type</th>\n      <th>number</th>\n      <th>is_correct</th>\n      <th>model</th>\n      <th>is_correct_rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24252710.jpg</td>\n      <td>1</td>\n      <td>24252710.0</td>\n      <td>0</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24295479.jpg</td>\n      <td>1</td>\n      <td>24295479.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24353013.jpg</td>\n      <td>1</td>\n      <td>24353013.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>24424020.jpg</td>\n      <td>1</td>\n      <td>24424020.0</td>\n      <td>0</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>24432064.jpg</td>\n      <td>1</td>\n      <td>24432064.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1446</th>\n      <td>98091358.jpg</td>\n      <td>1</td>\n      <td>98091358.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1448</th>\n      <td>98101173.jpg</td>\n      <td>1</td>\n      <td>98101173.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1450</th>\n      <td>98104730.jpg</td>\n      <td>1</td>\n      <td>98104730.0</td>\n      <td>0</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>98121817.jpg</td>\n      <td>1</td>\n      <td>98121817.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>98121833.jpg</td>\n      <td>1</td>\n      <td>98121833.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec[rec['is_correct_rec']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
