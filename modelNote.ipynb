{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 19:34:09,113 - modelscope - INFO - PyTorch version 2.0.1+cu117 Found.\n",
      "2023-10-14 19:34:09,116 - modelscope - INFO - TensorFlow version 2.14.0 Found.\n",
      "2023-10-14 19:34:09,117 - modelscope - INFO - Loading ast index from C:\\Users\\Олег\\.cache\\modelscope\\ast_indexer\n",
      "2023-10-14 19:34:09,283 - modelscope - INFO - Loading done! Current index file version is 1.9.2, with md5 d900a8624d792d555ed3cef91c01c35b and a total number of 941 components indexed\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from mmocr.apis import MMOCRInferencer\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "'''\n",
    "    detection_mode: ./models/custom_yolov8pt_25_orig.pt\n",
    "    rec_model: damo/cv_convnextTiny_ocr-recognition-general_damo\n",
    "    angle_rec_model: Aster\n",
    "'''\n",
    "\n",
    "det_res = None\n",
    "\n",
    "DETECTION_SAVE_PATH = './yolo_detections/results/crops/number/'\n",
    "MODEL_RESULT_PATH = './model_result/results.csv'\n",
    "\n",
    "BIN_TYPES = {\n",
    "    'ADAPTIVE_THRESH_GAUSSIAN_C': cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    'ADAPTIVE_THRESH_MEAN_C': cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    'THRESH_OTSU': cv2.THRESH_OTSU\n",
    "}\n",
    "\n",
    "# def get_center(bbox):\n",
    "#     return np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n",
    "#\n",
    "# def is_border_num(result, image_path):\n",
    "#         for i in range(len(result)):\n",
    "#             boxes = result[i].boxes.cpu().numpy()\n",
    "#             for box in boxes:\n",
    "#                 center = get_center(box.xyxy[0])\n",
    "#\n",
    "#\n",
    "#                 img = cv2.imread(image_path)\n",
    "#\n",
    "#                 if center[0] < (img.shape[1] / 10) or center[0] > (img.shape[1] / 10) * 9:\n",
    "#                     return True\n",
    "#             return False\n",
    "\n",
    "\n",
    "class NumberOcrModel:\n",
    "    def __init__(self, detection_model, rec_model, angle_rec_model):\n",
    "        self.detection_model = YOLO(detection_model)\n",
    "        self.rec_model = pipeline(Tasks.ocr_recognition, model=rec_model)\n",
    "        self.angle_rec_model = MMOCRInferencer(rec=angle_rec_model)\n",
    "\n",
    "        self.detection_result = None\n",
    "        self.img_path = None\n",
    "        self.image_name = None\n",
    "        self.bin_type = None\n",
    "        self.rec_result = None\n",
    "\n",
    "        self.prepare_model()\n",
    "\n",
    "    def prepare_model(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.detection_model.to('cuda')\n",
    "\n",
    "    def preprocess(self, image_path, image_name, bin_prep):\n",
    "        global det_res\n",
    "        detection_result = self.detection_model.predict(image_path, save = True, save_crop=True, project='yolo_detections', name='results', verbose=False)\n",
    "\n",
    "        det_res = detection_result\n",
    "\n",
    "        if detection_result and bin_prep:\n",
    "            img = cv2.imread(DETECTION_SAVE_PATH + image_name)\n",
    "            blur_img = cv2.GaussianBlur(img,(1,1),0)\n",
    "            bin_img = cv2.adaptiveThreshold(blur_img, 255, BIN_TYPES[bin_prep], cv2.THRESH_BINARY_INV, 29, -4)\n",
    "            cv2.imwrite(DETECTION_SAVE_PATH + image_name, bin_img)\n",
    "        return detection_result\n",
    "\n",
    "\n",
    "    def recognize(self, image_name, image_path, detected_data):\n",
    "        if not detected_data[0] or len(detected_data[0].cpu().numpy()) == 0:\n",
    "            # return [{\n",
    "            #     'filename': image_name,\n",
    "            #     'type': 0,\n",
    "            #     'number': 0,\n",
    "            #     'is_correct': 0,\n",
    "            #     'model': 'Recognition_model',\n",
    "            #     'is_correct_rec': False\n",
    "            # },\n",
    "            # {\n",
    "            #     'filename': image_name,\n",
    "            #     'type': 0,\n",
    "            #     'number': 0,\n",
    "            #     'is_correct': 0,\n",
    "            #     'model': 'Angle_recognition_model',\n",
    "            #     'is_correct_rec': False\n",
    "            # }]\n",
    "\n",
    "            return [\n",
    "                {\n",
    "                    'filename': image_name,\n",
    "                    'type': 0,\n",
    "                    'number': 0,\n",
    "                    'is_correct': 0,\n",
    "                    'model': '-',\n",
    "                    'is_correct_rec': False\n",
    "                }]\n",
    "\n",
    "        all_dirs = os.listdir('./yolo_detections')\n",
    "        max_length = len(max(all_dirs, key=len))\n",
    "        data_dir = sorted([x for x in all_dirs if len(x) == max_length])[-1]\n",
    "\n",
    "        crop_img_path = f'./yolo_detections/{data_dir}/crops/number/' + image_name\n",
    "\n",
    "        # if is_border_num(detected_data, image_path):\n",
    "        #     result = self.angle_rec_model(crop_img_path)\n",
    "        #     num =  re.sub(r'[^0-9]', '', result['predictions'][0]['rec_texts'][0])\n",
    "        #     model = 'Angle_recognition_model'\n",
    "        # else:\n",
    "        #     result = self.rec_model(crop_img_path)\n",
    "        #     num = re.sub(r'[^0-9]', '', result['text'][0])\n",
    "        #     model = 'Recognition_model'\n",
    "\n",
    "\n",
    "        result_1 = self.angle_rec_model(crop_img_path)\n",
    "        result_2 = self.rec_model(crop_img_path)\n",
    "\n",
    "        num_1 = re.sub(r'[^0-9]', '', result_1['predictions'][0]['rec_texts'][0]) # aster\n",
    "        num_2 = re.sub(r'[^0-9]', '', result_2['text'][0]) # model scope\n",
    "\n",
    "\n",
    "        # if len(num_2) == 8:\n",
    "        #     num_sub = num_2\n",
    "        # elif len(num_1) == 8:\n",
    "        #     num_sub = num_1\n",
    "        # elif len(num_2) > 8:\n",
    "        #     num_sub = num_2[:8]\n",
    "        # elif len(num_1) > 8:\n",
    "        #     num_sub = num_1[:8]\n",
    "        # elif not num_2:\n",
    "        #     num_sub = num_1\n",
    "        # elif not num_1:\n",
    "        #     num_sub = num_2\n",
    "        # elif len(num_2) < 8 and len(num_1) == 8:\n",
    "        #     num_sub = num_1\n",
    "        # else:\n",
    "        #     num_sub = num_2\n",
    "\n",
    "        if not num_2:\n",
    "            num_sub = num_1\n",
    "        elif num_1:\n",
    "            if len(num_2) >= 8:\n",
    "                num_sub = num_2[:8]\n",
    "            if len(num_2) < 8 and len(num_1) >= 8:\n",
    "                num_sub = num_1[:8]\n",
    "            if len(num_2) < 8 and len(num_1) < 8:\n",
    "                num_sub = num_2\n",
    "        else:\n",
    "            num_sub = num_2\n",
    "\n",
    "\n",
    "        result = [{\n",
    "            'filename': image_name,\n",
    "            'type': int(num_sub != None),\n",
    "            'number': (0, num_sub)[num_sub != None and num_sub != ''],\n",
    "            'is_correct': is_valid(num_sub),\n",
    "        }]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, img_path, bin_prep = None):\n",
    "        image_name = os.path.basename(os.path.normpath(img_path))\n",
    "        detected_data = self.preprocess(img_path, image_name, bin_prep)\n",
    "        return self.recognize(image_name, img_path, detected_data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 19:58:05,467 - modelscope - INFO - Model revision not specified, use revision: v2.3.0\n",
      "2023-10-14 19:58:06,012 - modelscope - INFO - initiate model from C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 19:58:06,014 - modelscope - INFO - initiate model from location C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo.\n",
      "2023-10-14 19:58:06,021 - modelscope - INFO - initialize model from C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 19:58:06,332 - modelscope - INFO - loading model from dir C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 19:58:06,501 - modelscope - INFO - loading model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmocr/textrecog/aster/aster_resnet45_6e_st_mj/aster_resnet45_6e_st_mj-cc56eca4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\temp\\Anaconda\\lib\\site-packages\\mmengine\\visualization\\visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "model = NumberOcrModel(\n",
    "    detection_model='./models/custom_yolov8x.pt',  # best(6).pt ./models/custom_yolov8pt_25_orig.pt\n",
    "    rec_model='damo/cv_convnextTiny_ocr-recognition-general_damo',\n",
    "    angle_rec_model='Aster'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results896\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad3736d75a6b4ab7925c379c185c58c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': '28822880.jpg', 'type': 1, 'number': 0, 'is_correct': 0}]\n"
     ]
    }
   ],
   "source": [
    "test_res = model.predict('./test_images/28822880.jpg')\n",
    "print(test_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'number'}\n orig_img: array([[[101,  80, 105],\n         [125, 104, 129],\n         [144, 123, 148],\n         ...,\n         [240, 198, 131],\n         [240, 198, 131],\n         [240, 198, 131]],\n \n        [[111,  90, 115],\n         [130, 109, 134],\n         [145, 124, 149],\n         ...,\n         [240, 198, 131],\n         [240, 198, 131],\n         [240, 198, 131]],\n \n        [[124, 103, 128],\n         [137, 116, 141],\n         [144, 123, 148],\n         ...,\n         [240, 198, 131],\n         [240, 198, 131],\n         [240, 198, 131]],\n \n        ...,\n \n        [[101,  97,  96],\n         [ 78,  74,  73],\n         [ 66,  62,  61],\n         ...,\n         [143, 128, 125],\n         [125, 108, 105],\n         [111,  94,  91]],\n \n        [[ 87,  83,  82],\n         [ 96,  92,  91],\n         [116, 112, 111],\n         ...,\n         [141, 126, 123],\n         [125, 108, 105],\n         [110,  93,  90]],\n \n        [[ 81,  77,  76],\n         [ 98,  94,  93],\n         [132, 128, 127],\n         ...,\n         [141, 126, 123],\n         [124, 107, 104],\n         [110,  93,  90]]], dtype=uint8)\n orig_shape: (1080, 1920)\n path: 'C:\\\\Users\\\\Олег\\\\Documents\\\\GitHub\\\\wagon-number-ocr\\\\test_images\\\\28822880.jpg'\n probs: None\n save_dir: 'yolo_detections\\\\results896'\n speed: {'preprocess': 5.000591278076172, 'inference': 88.00029754638672, 'postprocess': 3.0028820037841797}]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def is_valid(result):\n",
    "    if not result:\n",
    "        return 0\n",
    "\n",
    "    cont_sum = 0\n",
    "    control_num = -1\n",
    "\n",
    "    if len(result) == 8:\n",
    "        control_num = int(result[-1:])\n",
    "        cont_sum = 0\n",
    "        for i in range(7):\n",
    "            num = int(result[i]) * (2, 1)[i % 2 == 1]\n",
    "            if num >= 10:\n",
    "                cont_sum += sum(list(map(int, set(str(num)))))\n",
    "            else:\n",
    "                cont_sum += num\n",
    "    return int((cont_sum % 10 == 0 and control_num == 0) or (10 - cont_sum % 10) == control_num)\n",
    "\n",
    "\n",
    "def to_csv(results):\n",
    "    with open(MODEL_RESULT_PATH, 'w', encoding='UTF8') as f:\n",
    "        fields = ('filename', 'type', 'number', 'is_correct')  # 'model', 'is_correct_rec'\n",
    "        writer = csv.DictWriter(f, fieldnames=fields, lineterminator = '\\n')\n",
    "        writer.writeheader()\n",
    "        for res in results:\n",
    "            writer.writerow(res[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results862\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbca7819872248bb8f45647ab67c6cf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results863\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1374189f1ffd40ecbbd3ece173af9186"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results864\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05bb27282c964546ac84352e9933cea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results865\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfb01b5203ec4dbcb234d4baa33de607"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results866\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15dfb01418fa4ec68b29b12e887c8006"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results867\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6d8601b473d4c18ad1103b07d855516"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results868\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed0b95a78a414a1faf1e55ea89928e51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results869\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0600575e463944ab9e219452afabd055"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1myolo_detections\\results870\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a9941b02f324051b546a7c8e24db09f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       filename  type    number  is_correct              model  is_correct_rec\n",
      "0  28005312.jpg     1  28005312           1  Recognition_model            True\n",
      "1  28008332.jpg     1  28008332           1  Recognition_model            True\n",
      "2  28025021.jpg     1  28025021           1  Recognition_model            True\n",
      "3  29025210.jpg     1  29025210           1  Recognition_model            True\n",
      "4  29029972.jpg     1  29029972           1  Recognition_model            True\n",
      "5  29051091.jpg     1  29051091           1  Recognition_model            True\n",
      "6  42026633.jpg     1  42026633           1  Recognition_model            True\n",
      "7  42026781.jpg     1  42026781           1  Recognition_model            True\n",
      "8  42026872.jpg     1  42026872           1  Recognition_model            True\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './test_images/'\n",
    "\n",
    "images = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(DATA_PATH):\n",
    "    images.extend(filenames)\n",
    "\n",
    "results = []\n",
    "\n",
    "for img in images:\n",
    "    res = model.predict(DATA_PATH + img)\n",
    "    if res:\n",
    "        results.append(res)\n",
    "\n",
    "to_csv(results)\n",
    "\n",
    "file = pd.read_csv(MODEL_RESULT_PATH)\n",
    "print(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "line = re.sub(r'[^0-9]', '', '1,2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "line"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = 'sdfsdf.jpg'\n",
    "a[:-4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('./results.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7152777777777778\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "import re\n",
    "\n",
    "for index, row in file.iterrows():\n",
    "    if re.sub(r'[^0-9]', '', row['filename']) == re.sub(r'[^0-9]', '',  str(row['number'])[:8]):\n",
    "        count += 1\n",
    "\n",
    "print(f'Score: {count / len(file)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "594"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m file[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_correct_rec\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\temp\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   9557\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m   9559\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m   9560\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   9561\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   9566\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m   9567\u001B[0m )\n\u001B[1;32m-> 9568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\temp\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py:764\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[1;32m--> 764\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\temp\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py:891\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 891\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    893\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[1;32mC:\\temp\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py:907\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    905\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m    906\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m--> 907\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    908\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m    909\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m    910\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m    911\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m file[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_correct_rec\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39mfile\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m x[\u001B[38;5;241m2\u001B[39m])\n",
      "\u001B[1;31mIndexError\u001B[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "file['is_correct_rec']=file.apply(lambda x: x[0][:-4] == x[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "          filename  type      number  is_correct              model  \\\n0     24252710.jpg     1  24252710.0           0  Recognition_model   \n2     24295479.jpg     1  24295479.0           1  Recognition_model   \n4     24353013.jpg     1  24353013.0           1  Recognition_model   \n6     24424020.jpg     1  24424020.0           0  Recognition_model   \n8     24432064.jpg     1  24432064.0           1  Recognition_model   \n...            ...   ...         ...         ...                ...   \n1446  98091358.jpg     1  98091358.0           1  Recognition_model   \n1448  98101173.jpg     1  98101173.0           1  Recognition_model   \n1450  98104730.jpg     1  98104730.0           0  Recognition_model   \n1454  98121817.jpg     1  98121817.0           1  Recognition_model   \n1456  98121833.jpg     1  98121833.0           1  Recognition_model   \n\n      is_correct_rec  \n0               True  \n2               True  \n4               True  \n6               True  \n8               True  \n...              ...  \n1446            True  \n1448            True  \n1450            True  \n1454            True  \n1456            True  \n\n[500 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>type</th>\n      <th>number</th>\n      <th>is_correct</th>\n      <th>model</th>\n      <th>is_correct_rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24252710.jpg</td>\n      <td>1</td>\n      <td>24252710.0</td>\n      <td>0</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24295479.jpg</td>\n      <td>1</td>\n      <td>24295479.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24353013.jpg</td>\n      <td>1</td>\n      <td>24353013.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>24424020.jpg</td>\n      <td>1</td>\n      <td>24424020.0</td>\n      <td>0</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>24432064.jpg</td>\n      <td>1</td>\n      <td>24432064.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1446</th>\n      <td>98091358.jpg</td>\n      <td>1</td>\n      <td>98091358.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1448</th>\n      <td>98101173.jpg</td>\n      <td>1</td>\n      <td>98101173.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1450</th>\n      <td>98104730.jpg</td>\n      <td>1</td>\n      <td>98104730.0</td>\n      <td>0</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>98121817.jpg</td>\n      <td>1</td>\n      <td>98121817.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>98121833.jpg</td>\n      <td>1</td>\n      <td>98121833.0</td>\n      <td>1</td>\n      <td>Recognition_model</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec[rec['is_correct_rec']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
