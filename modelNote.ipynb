{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 09:11:21,902 - modelscope - INFO - PyTorch version 2.0.1+cu117 Found.\n",
      "2023-10-14 09:11:21,905 - modelscope - INFO - TensorFlow version 2.14.0 Found.\n",
      "2023-10-14 09:11:21,906 - modelscope - INFO - Loading ast index from C:\\Users\\Олег\\.cache\\modelscope\\ast_indexer\n",
      "2023-10-14 09:11:22,071 - modelscope - INFO - Loading done! Current index file version is 1.9.2, with md5 d900a8624d792d555ed3cef91c01c35b and a total number of 941 components indexed\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from mmocr.apis import MMOCRInferencer\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "'''\n",
    "    detection_mode: ./models/custom_yolov8pt_25_orig.pt\n",
    "    rec_model: damo/cv_convnextTiny_ocr-recognition-general_damo\n",
    "    angle_rec_model: Aster\n",
    "'''\n",
    "\n",
    "DETECTION_SAVE_PATH = './yolo_detections/results/crops/number/'\n",
    "\n",
    "BIN_TYPES = {\n",
    "    'ADAPTIVE_THRESH_GAUSSIAN_C': cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    'ADAPTIVE_THRESH_MEAN_C': cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    'THRESH_OTSU': cv2.THRESH_OTSU\n",
    "}\n",
    "\n",
    "class NumberOcrModel:\n",
    "    def __init__(self, detection_model, rec_model, angle_rec_model):\n",
    "        self.detection_model = YOLO(detection_model)\n",
    "        self.rec_model = pipeline(Tasks.ocr_recognition, model=rec_model)\n",
    "        self.angle_rec_model = MMOCRInferencer(rec=angle_rec_model)\n",
    "\n",
    "        self.detection_result = None\n",
    "        self.img_path = None\n",
    "        self.image_name = None\n",
    "        self.bin_type = None\n",
    "\n",
    "        model.prepare_model()\n",
    "\n",
    "    def prepare_model(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.detection_model.to('cuda')\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.image_name = os.path.basename(os.path.normpath(self.img_path))\n",
    "\n",
    "        result = self.detection_model.predict(self.img_path, save = True, save_crop=True, project='yolo_detections', name='results')\n",
    "        self.detection_result = result\n",
    "\n",
    "        if self.bin_type:\n",
    "            img = cv2.imread(DETECTION_SAVE_PATH + self.image_name)\n",
    "            blur_img = cv2.GaussianBlur(img,(1,1),0)\n",
    "            bin_img = cv2.adaptiveThreshold(blur_img, 255, BIN_TYPES[self.bin_type], cv2.THRESH_BINARY_INV, 29, -4)\n",
    "            cv2.imwrite(DETECTION_SAVE_PATH + self.image_name, bin_img)\n",
    "\n",
    "    def recognize(self):\n",
    "        rec_result = self.rec_model(DETECTION_SAVE_PATH + self.image_name)\n",
    "        angle_rec_result = self.angle_rec_model(DETECTION_SAVE_PATH + self.image_name)\n",
    "\n",
    "        result = {\n",
    "            'Recognition_model': rec_result,\n",
    "            'Angele_recognition_model': angle_rec_result,\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, img_path, bin_type = None):\n",
    "        self.img_path = img_path\n",
    "        self.bin_type = bin_type\n",
    "\n",
    "        self.preprocess()\n",
    "        return self.recognize()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 09:42:11,916 - modelscope - INFO - Model revision not specified, use revision: v2.3.0\n",
      "2023-10-14 09:42:12,483 - modelscope - INFO - initiate model from C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 09:42:12,485 - modelscope - INFO - initiate model from location C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo.\n",
      "2023-10-14 09:42:12,492 - modelscope - INFO - initialize model from C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 09:42:12,716 - modelscope - INFO - loading model from dir C:\\Users\\Олег\\.cache\\modelscope\\hub\\damo\\cv_convnextTiny_ocr-recognition-general_damo\n",
      "2023-10-14 09:42:12,841 - modelscope - INFO - loading model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmocr/textrecog/aster/aster_resnet45_6e_st_mj/aster_resnet45_6e_st_mj-cc56eca4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\temp\\Anaconda\\lib\\site-packages\\mmengine\\visualization\\visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "model = NumberOcrModel(\n",
    "    detection_model='./models/custom_yolov8pt_25_orig.pt',\n",
    "    rec_model='damo/cv_convnextTiny_ocr-recognition-general_damo',\n",
    "    angle_rec_model='Aster'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\\\PycharmProjects\\Wagon_number_OCR\\data\\63098560.jpg: 480x800 1 number, 807.0ms\n",
      "Speed: 5.0ms preprocess, 807.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "Results saved to \u001B[1myolo_detections\\results3\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe8b9265e4c04d6582d175481fc67503"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'Recognition_model': {'text': ['63098560']},\n 'Angele_recognition_model': {'predictions': [{'rec_texts': ['63098560'],\n    'rec_scores': [0.9945330023765564]}],\n  'visualization': []}}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('./data/63098560.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
